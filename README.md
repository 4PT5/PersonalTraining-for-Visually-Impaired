# PersonalTraining for Visually Impaired

![4pt5](https://i.esdrop.com/d/j09wmqn009xs/fRGaFyj08q.png)
<br>
**PersonalTraining for Visually Imapired**ì€ ***2021 ê³µê°œSW ê°œë°œì ëŒ€íšŒ***ë¥¼ ìœ„í•œ í”„ë¡œì íŠ¸ë¡œ, ì‚¬íšŒë¬¸ì œí˜• ê³¼ì œ ê°€ìš´ë° ì‚¬íšŒì  ì•½ìë¥¼ ìœ„í•œ ì‹œìŠ¤í…œì´ë‹¤. í•´ë‹¹ í”„ë¡œì íŠ¸ëŠ” ì‹œê° ì¥ì• ì¸ì„ ìœ„í•œ í¼ìŠ¤ë„ íŠ¸ë ˆì´ë‹(PT) ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ ì˜ìƒì²˜ë¦¬ì™€ ìŒì„±ì¸ì‹ë§Œìœ¼ë¡œë„ ì‚¬ìš©ìê°€ ìš´ë™í•  ìˆ˜ ìˆë„ë¡ ë„ì›€ì„ ì£¼ê¸° ìœ„í•œ ëª©ì ìœ¼ë¡œ ì§„í–‰ëœë‹¤.

**PersonalTraining for Visually Imapired** is a project for the ***2021 Open SW Developer Conference*** and is a system for the socially disadvantaged among social problem-type tasks. In order to provide personal training services for visually impaired people, which include low vision, it helps users to exercise only through voice recognition and image processing.

## Table of Contents
* [Getting Started](#getting-started)
* [System Architecture](#system-architecture)
* [Introduction](#introduction)
  + [Project purpose](#project-purpose)
  + [Description](#description)
  + [Operation Process](#operation-process)
* [Tech Skills and Tools](#tech-skills-and-tools)
* [Browser Support](#browser-support)
* [Contributors](#contributors)
* [Demo](#demo)
* [License](#license)

## Getting Started

```
$ git clone https://github.com/4PT5/PersonalTraining-for-Visually-Impaired
```
### Pip
```
$ python3 -m venv django_venv
$ source django_venv/bin/activate
(django_venv) $ pip install -r requirements.txt
(django_venv) $ python manage.py migrate
(django_venv) $ python manage.py createsuperuser
(django_venv) $ python manage.py runserver
# Load the site at http://127.0.0.1:8000/
```
requirements.txt should have the following line:
```
tensorflow==1.15.5
```

## System Architecture
<img src="https://i.esdrop.com/d/j09wmqn009xs/TZtVCFOK9u.png" width="80%" height="60%">

## Introduction
### Project purpose
> AIë¥¼ ì´ìš©í•œ ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ì¼€ì–´ ì‚°ì—…ì€ ë§¤ìš° ë¹ ë¥¸ ì†ë„ë¡œ ì„±ì¥í•˜ê³  ìˆë‹¤. í•˜ì§€ë§Œ ê·¸ì¤‘ ì‹œê° ì¥ì• ì¸ì„ ìœ„í•œ ìƒí’ˆì„ ì°¾ê¸°ëŠ” ì‰½ì§€ ì•Šë‹¤. ê·¸ë“¤ì—ê²Œ ìˆì–´ TV, ìŠ¤ë§ˆíŠ¸í°, ëª¨ë‹ˆí„° í™”ë©´ì„ ë³´ëŠ” ê²ƒì€ ì–´ë µê±°ë‚˜ í˜¹ì€ ë¶ˆê°€ëŠ¥í•œ ì¼ì´ê¸° ë•Œë¬¸ì— í•´ë‹¹ ì œí’ˆë“¤ì— ëŒ€í•œ ì ‘ê·¼ì„±ê³¼ ê³µê¸‰ì€ ë§¤ìš° ë‚®ì„ ìˆ˜ ë°–ì— ì—†ë‹¤. ë³¸ í”„ë¡œì íŠ¸ëŠ” ì‹œê°ì¥ì• ì¸ë“¤ì´ í™ˆíŠ¸ë ˆì´ë‹ì„ í•  ìˆ˜ ìˆë„ë¡ ìš´ë™ì„ ë³´ì¡°í•˜ëŠ” ì„œë¹„ìŠ¤ë¥¼ ì œì•ˆí•œë‹¤. ì˜ìƒì²˜ë¦¬ë¥¼ í†µí•œ ìš´ë™ ìì„¸ êµì • ì„œë¹„ìŠ¤ëŠ” ë„ë¦¬ ìˆì§€ë§Œ, ë³¸ í”„ë¡œì íŠ¸ê°€ ì œì•ˆí•˜ëŠ” ì„œë¹„ìŠ¤ì˜ ì°¨ë³„ì ì€ ì‹œê°ì¥ì• ì¸ ë¶„ë“¤ì„ ìœ„í•´ ìŒì„±ì²˜ë¦¬ë¥¼ í™œìš©í•˜ì—¬ ìì„¸ êµì •ì„ ì œê³µí•œë‹¤ëŠ” ì ì´ë‹¤.

> The smart healthcare industry using AI is developing at a very rapid rate. Among them, however, products for visually impaired people are not easily found. For them, it is difficult or impossible to watch TV, smartphone, or monitor screens, so accessibility and supply for those products are inevitably low.
This project proposes a service to assist the blind in home training. Although the exercise posture correction service through video processing is widely used, the distinction of the service proposed by this project is that it provides posture correction using voice processing for blind people.

### Description
> 1ï¸âƒ£ **ì‹œê°ì¥ì• ì¸ì„ ìœ„í•œ ìŒì„± ì•ˆë‚´**   
ë³¸ í”„ë¡œì íŠ¸ëŠ” í™”ë©´ ì† ì˜ìƒì„ ë³¼ ìˆ˜ ì—†ëŠ” ì‹œê°ì¥ì• ì¸ë“¤ì€ ë‹¨ìˆœíˆ ìš´ë™ ì˜ìƒì„ í‹€ì–´ë†“ê³  ê·€ë¡œ ë“£ëŠ” ê²ƒë§Œìœ¼ë¡œëŠ” í•´ë‹¹ ë™ì‘ì„ ë”°ë¼í•  ìˆ˜ ì—†ë‹¤ëŠ” ì ì— ì§‘ì¤‘í•˜ì˜€ë‹¤. ì´ì— ë”°ë¼ ì‚¬ìš©ìê°€ ëˆˆì— ë³´ì´ëŠ” ì˜ìƒ ì—†ì´ë„ ì •í™•í•œ ìš´ë™ ìì„¸ë¥¼ ì¡ì„ ìˆ˜ ìˆë„ë¡, ìš´ë™ ë™ì‘ì— ëŒ€í•œ íŒ”ê³¼ ë‹¤ë¦¬ì˜ êµ¬ë¶€ë¦¬ëŠ” ì •ë„, í—ˆë¦¬ë¥¼ ìˆ™ì´ëŠ” ì •ë„, ë¬´ë¦ì„ ë‚´ë¯¸ëŠ” ì •ë„ ë“± ì„¸ì„¸í•œ ìì„¸ì— ëŒ€í•œ ì„¤ëª…ì„ ë¨¼ì € ëª©ì†Œë¦¬ë¡œ ì•ˆë‚´í•  ìˆ˜ ìˆê²Œ ì„¤ê³„í–ˆë‹¤.    
2ï¸âƒ£ **ìš´ë™ ìì„¸ì— ëŒ€í•œ ì‹¤ì‹œê°„ ê°ì§€**  
ì‚¬ìš©ìëŠ” ì•ˆë‚´ë˜ëŠ” ìŒì„±ì„ í†µí•´ ê° ì‹ ì²´ë¶€ìœ„ì— ë”°ë¼ ì„¤ëª…í•˜ëŠ” ìì„¸ë¥¼ ì¡ì„ ìˆ˜ ìˆê³ , ì´ëŠ” ì›¹ìº ì„ í†µí•´ ì…ë ¥ë˜ì–´ í”„ë¡œê·¸ë¨ ë‚´ì—ì„œ ìì„¸ ì¶”ì • ë° í•´ë‹¹ ìì„¸ì— ëŒ€í•œ í”¼ë“œë°±ì´ ì´ë£¨ì–´ì§„ë‹¤.  
3ï¸âƒ£ **ì‹œê°ì¥ì• ì¸ì„ ê³ ë ¤í•œ ë‹¨ìˆœí•œ UI**  
ë˜í•œ ë³¸ í”„ë¡œì íŠ¸ì—ì„œëŠ” ì‹œê° ì¥ì• ì¸ ê°€ìš´ë° 90%ê°€ ì €ì‹œë ¥ìì¸ ê²ƒì„ ê°ì•ˆí–ˆë‹¤. ê·¸ë˜ì„œ ì €ì‹œë ¥ìë“¤ì„ ìœ„í•œ ë‹¨ìˆœí•œ UIë¥¼ ì œê³µí•œë‹¤. ì›¹ í˜ì´ì§€ëŠ” í° ê¸€ì”¨ë¡œ ëª¨ë“  ê¸€ìë“¤ì´ ì‘ì„±ë˜ì–´ ìˆê³ , ëˆˆì— ì‰½ê²Œ ë„ë„ë¡ í° ë²„íŠ¼ì„ ë°°ì¹˜í–ˆìœ¼ë©°, í˜ì´ì§€ ì´ë™ì´ ê±°ì˜ ì—†ë„ë¡ ì›¹ì„ êµ¬ì„±í•˜ì—¬ ì‚¬ìš©ìë“¤ì´ ì´ìš©í•˜ëŠ” ë° ì–´ë µì§€ ì•Šë„ë¡ êµ¬ì¶•í–ˆë‹¤.  

> 1ï¸âƒ£ **Voice guidance for blind people**  
The project focused on the fact that visually impaired people who cannot see the video on the screen cannot follow the motion simply by playing the exercise video and listening to it with their ears. Accordingly, it is designed to guide the user through detailed explanations such as the degree of bending of arms and legs, bending of waist, and sticking out of knees so that the user can get an accurate exercise position without visible video.  
2ï¸âƒ£ **Real-time detection of posture**  
The guided voice allows the user to correct the posture described according to each body part, which is inputted through a webcam to provide postural estimation and feedback on the posture within the program.  
3ï¸âƒ£ **Simple UI**   
The project also considered that 90% of the visually impaired people were low vision. So it provides a simple UI for low vision people. The web page is written in large letters, has large buttons that are easily visible, and has almost no movement between pages so that it is not difficult for users to use.

### Operation Process
> **[ìŒì„±] ìš´ë™ ì„ íƒ â¡ï¸ [ì˜ìƒ] ìì„¸ ì¸¡ì • ë° ë¶„ì„ â¡ï¸ [ìŒì„±] í”¼ë“œë°± â¡ï¸ [ì˜ìƒ] ì¹´ìš´íŒ…**   
ì‚¬ìš©ìëŠ” ì œì‹œë˜ëŠ” ìš´ë™ë“¤ ì¤‘ ì›í•˜ëŠ” ìš´ë™ì„ ìŒì„±ìœ¼ë¡œ ì„ íƒí•˜ì—¬ ìš´ë™ì„ ì§„í–‰í•  ìˆ˜ ìˆë‹¤.  
í”„ë¡œê·¸ë¨ì€ ìì„¸ë¥¼ ìŒì„±ìœ¼ë¡œ ì„¤ëª…í•´ì¤€ ë’¤, ì‚¬ìš©ìì˜ ìì„¸ë¥¼ ì›¹ìº ìœ¼ë¡œ ì…ë ¥ë°›ëŠ”ë‹¤.  
ì…ë ¥ ë°›ì€ ì›¹ìº  ì˜ìƒì„ tensorflow-posenet ë¹„ì „ ëª¨ë¸ì„ í†µí•´ ë”¥ëŸ¬ë‹ í•˜ì—¬ ì¶”ì •ë˜ëŠ” ì‹ ì²´ì˜ 17ê°œ íŠ¹ì§•ì ì„ í†µí•´ ì •í™•í•œ ìì„¸ì™€ ì‚¬ìš©ìì˜ ìì„¸ë¥¼ ë¹„êµí•˜ê³ , ìŒì„±ìœ¼ë¡œ ì‹¤ì‹œê°„ í”¼ë“œë°± í•´ì¤€ë‹¤.   
ì´ ê³¼ì •ì„ í†µí•´ ì‚¬ìš©ìê°€ ì •í™•í•œ ìì„¸ë¥¼ ì¡ìœ¼ë©´, ì´í›„ ìš´ë™ì„ ê³„ì†í•´ì„œ ì§„í–‰í•˜ê³  ë™ì‘ íšŸìˆ˜ë¥¼ ì¹´ìš´íŒ…í•œë‹¤.   
í•´ë‹¹ ì‹œìŠ¤í…œì€ ì›¹ í˜ì´ì§€ì—ì„œ êµ¬ë™ëœë‹¤.
  
> **[Voice] Motion Selection â¡ï¸ [Image] Position Measurement and Analysis â¡ï¸ [Voice] Feedback â¡ï¸ [Image] Counting**  
The user can proceed the exercise by selecting the desired exercise in voice among the exercises presented.  
The program explains the posture with voice, and then the user's posture is entered into a webcam.  
Deep learning of inputted webcam images through the tensorflow-posenet vision model allows accurate posture and user posture to be compared through 17 characteristics of the body, and provides real-time feedback in voice.  
Through this process, when the user is in the correct position, the exercise continues and counts the number of movements.  
The system runs on web.

## Tech Skills and Tools
<p align="center">
 <img src="https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=Python&logoColor=white"/></a> 
 <img src="https://img.shields.io/badge/Django-092E20?style=flat-square&logo=Django&logoColor=white"/></a> 
 <img src="https://img.shields.io/badge/TensorFlow-FF6F00?style=flat-square&logo=TensorFlow&logoColor=white"/></a> 
 <img src="https://img.shields.io/badge/NGINX-009639?style=flat-square&logo=NGINX&logoColor=white"/></a> 
 <img src="https://img.shields.io/badge/HTML5-E34F26?style=flat-square&logo=HTML5&logoColor=white"/></a> 
 <img src="https://img.shields.io/badge/CSS3-1572B6?style=flat-square&logo=CSS3&logoColor=white"/></a> 
 <img src="https://img.shields.io/badge/Bootstrap-7952B3?style=flat-square&logo=Bootstrap&logoColor=white"/></a> 
 <img src="https://img.shields.io/badge/Git-F05032?style=flat-square&logo=Git&logoColor=white"/></a> 
 <img src="https://img.shields.io/badge/GitHub-181717?style=flat-square&logo=GitHub&logoColor=white"/></a> 
 <img src="https://img.shields.io/badge/Visual Studio Code-007ACC?style=flat-square&logo=Visual Studio Code&logoColor=white"/></a> 
</p>

*Language:* Python 3.7  
*Framework:* Django 3.2.7  
*STT/TTS:* python-speech-recognition  
*Image Processing:* openCV 3.4.13, tensorflow-posenet 1.15.5 

## Browser Support
![Chrome](https://raw.githubusercontent.com/alrra/browser-logos/master/src/chrome/chrome_48x48.png) | ![IE](https://raw.githubusercontent.com/alrra/browser-logos/master/src/edge/edge_48x48.png) |
--- | --- |
Latest âœ”| 10+ âœ” |

## Contributors
All participants in this project are majoring in Computer Science Engieneering, Dongguk UniversityğŸ«

| Name                  | Email                  | Github                            | Role                          |
|-----------------------|------------------------|-----------------------------------|-------------------------------|
| ğŸ‘§ğŸ» DongYeon Kang      | myjjue00@gmail.com     | https://github.com/dongyeon-0822  | Front-end, Speech Recognition |
| ğŸ•µğŸ¼â€â™€ MinSeong Kang     | kdsvip5@naver.com      | https://github.com/minnseong      | Back-end, Image Processing    |
| ğŸ‘±ğŸ»â€â™€ï¸ Hyewon Kang       | gpffps369@gmail.com    | https://github.com/HyewonKkang    | Front-end, Speech Recognition |
| ğŸ‘¨ğŸ»â€ğŸ¦³ Woosung Kim       | woosung0420k@naver.com | https://github.com/WoosungMichael | Back-end, Image Processing    |
| ğŸ‘©ğŸ»â€ğŸ’» Sua Jang (Leader) | sooa9918@dgu.ac.kr     | https://github.com/sua1223        | Back-end, Image Processing    |

## Demo
[Youtube-Link](https://www.youtube.com/watch?v=2aFOzoOaKmU)

## License
PersonalTraining-for-Visually-Impaired is released under the Apache License 2.0.
